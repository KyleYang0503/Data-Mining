{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8f9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "data_id = pd.read_csv(data_path + 'data_identification.csv')\n",
    "emotions = pd.read_csv(data_path + 'emotion.csv')\n",
    "sample_sub = pd.read_csv(data_path + 'sampleSubmission.csv')\n",
    "tweets = pd.read_json(data_path + 'tweets_DM.json', lines=True)\n",
    "tweets_important = pd.DataFrame(tweets._source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510973cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list = tweets_important['_source'].to_list()\n",
    "tmp_df = pd.DataFrame.from_records(tw_list) #dict list to dataframe\n",
    "tmp_df_list = tmp_df['tweet'].to_list()\n",
    "final_tweet_df = pd.DataFrame.from_records(tmp_df_list)\n",
    "df_final = pd.merge(final_tweet_df, data_id, how='outer', on='tweet_id').merge(emotions, how='outer', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51783016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hashtags  tweet_id  \\\n",
       "0                             [Snapchat]  0x376b20   \n",
       "1          [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                           [bibleverse]  0x28b412   \n",
       "3                                     []  0x1cd5b0   \n",
       "4                                     []  0x2de201   \n",
       "...                                  ...       ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                               []  0x29d0cb   \n",
       "1867532                               []  0x2a6a4f   \n",
       "1867533                               []  0x24faed   \n",
       "1867534                    [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0        People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1        @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "2        Confident of your obedience, I write to you, k...           test   \n",
       "3                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>          train   \n",
       "4        \"Trust is not the same as faith. A friend is s...           test   \n",
       "...                                                    ...            ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...           test   \n",
       "1867531  I swear all this hard work gone pay off one da...           test   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...           test   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...          train   \n",
       "1867534             Blessed to be living #Sundayvibes <LH>          train   \n",
       "\n",
       "              emotion  \n",
       "0        anticipation  \n",
       "1             sadness  \n",
       "2                 NaN  \n",
       "3                fear  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "1867530           NaN  \n",
       "1867531           NaN  \n",
       "1867532           NaN  \n",
       "1867533           joy  \n",
       "1867534           joy  \n",
       "\n",
       "[1867535 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2714baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anticipation': 0, 'sadness': 1, nan: 2, 'fear': 3, 'joy': 4, 'anger': 5, 'trust': 6, 'disgust': 7, 'surprise': 8}\n",
      "{0: 'anticipation', 1: 'sadness', 2: nan, 3: 'fear', 4: 'joy', 5: 'anger', 6: 'trust', 7: 'disgust', 8: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "emotion2idx = {}\n",
    "idx2emotion = {}\n",
    "for i, emotion in enumerate(df_final['emotion'].unique()):\n",
    "    emotion2idx[emotion] = i\n",
    "    idx2emotion[i] = emotion\n",
    "\n",
    "print(emotion2idx)\n",
    "print(idx2emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p \n",
    "def preprocess_tweet(text):\n",
    "    text_ = []\n",
    "    for t in text.split():\n",
    "        if t == '<LH>':\n",
    "            continue\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        t = t.lower()        \n",
    "        text_.append(t)\n",
    "    return \" \".join(text_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9e48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = df_final.iloc[10].text\n",
    "#print(text)\n",
    "#print(preprocess_tweet(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ecfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['text'] = df_final['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7e0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_final[df_final['identification'] == 'train']\n",
    "test_df = df_final[df_final['identification'] == 'test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5ffea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.replace('NaN', np.nan)\n",
    "train_df = train_df.dropna(subset=['emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115eeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test.csv', index=False)\n",
    "train_df.to_csv('train.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
